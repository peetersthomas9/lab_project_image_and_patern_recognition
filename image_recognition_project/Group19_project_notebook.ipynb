{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Important-notes\" data-toc-modified-id=\"Important-notes--1\">Important notes</a></span></li><li><span><a href=\"#0.-Introduction\" data-toc-modified-id=\"0.-Introduction-0\">0. Introduction</a></span></li><li><span><a href=\"#1.-Rules\" data-toc-modified-id=\"1.-Rules-1\">1. Rules</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Standard\" data-toc-modified-id=\"1.1-Standard-1.1\">1.1 Standard</a></span></li><li><span><a href=\"#1.2-Advanced\" data-toc-modified-id=\"1.2-Advanced-1.2\">1.2 Advanced</a></span></li><li><span><a href=\"#1.3-Notes\" data-toc-modified-id=\"1.3-Notes-1.3\">1.3 Notes</a></span></li></ul></li><li><span><a href=\"#2.-Data\" data-toc-modified-id=\"2.-Data-2\">2. Data</a></span></li><li><span><a href=\"#3.-Your-Tasks\" data-toc-modified-id=\"3.-Your-Tasks-3\">3. Your Tasks</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Example-Final-results\" data-toc-modified-id=\"3.1-Example-Final-results-3.1\">3.1 Example Final results</a></span></li><li><span><a href=\"#3.2-Example-Accuracy\" data-toc-modified-id=\"3.2-Example-Accuracy-3.2\">3.2 Example Accuracy</a></span></li></ul></li><li><span><a href=\"#4-Our-implementation\" data-toc-modified-id=\"4-Our-implementation-4\">4 Our implementation</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.0-Data-extraction\" data-toc-modified-id=\"4.0-Data-extraction-4.1\">4.0 Data extraction</a></span></li><li><span><a href=\"#4.1-Card-and-dealer-localisation\" data-toc-modified-id=\"4.1-Card-and-dealer-localisation-4.2\">4.1 Card and dealer localisation</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1.1-Dealer\" data-toc-modified-id=\"4.1.1-Dealer-4.2.1\">4.1.1 Dealer</a></span></li></ul></li><li><span><a href=\"#4.1.2-Card\" data-toc-modified-id=\"4.1.2-Card-4.3\">4.1.2 Card</a></span></li><li><span><a href=\"#4.2-Image-preprocessing\" data-toc-modified-id=\"4.2-Image-preprocessing-4.4\">4.2 Image preprocessing</a></span></li><li><span><a href=\"#4.3-Neural-Network-for-mnist-numbers\" data-toc-modified-id=\"4.3-Neural-Network-for-mnist-numbers-4.5\">4.3 Neural Network for mnist numbers</a></span></li><li><span><a href=\"#4.4-Pattern-Recognition-for-card-symbols\" data-toc-modified-id=\"4.4-Pattern-Recognition-for-card-symbols-4.6\">4.4 Pattern Recognition for card symbols</a></span></li><li><span><a href=\"#4.5-Creating-an-overlay\" data-toc-modified-id=\"4.5-Creating-an-overlay-4.7\">4.5 Creating an overlay</a></span></li><li><span><a href=\"#4.6-Points-with-standard-rule\" data-toc-modified-id=\"4.6-Points-with-standard-rule-4.8\">4.6 Points with standard rule</a></span></li><li><span><a href=\"#4.7-Points-with-advanced-rule\" data-toc-modified-id=\"4.7-Points-with-advanced-rule-4.9\">4.7 Points with advanced rule</a></span></li><li><span><a href=\"#4.8-Pipeline-+-Output\" data-toc-modified-id=\"4.8-Pipeline-+-Output-4.10\">4.8 Pipeline + Output</a></span></li></ul></li><li><span><a href=\"#5-Annexe\" data-toc-modified-id=\"5-Annexe-5\">5 Annexe</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1-Extract-game-data\" data-toc-modified-id=\"5.1-Extract-game-data-5.1\">5.1 Extract game data</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1.1-Extract-all-data\" data-toc-modified-id=\"5.1.1-Extract-all-data-5.1.1\">5.1.1 Extract all data</a></span></li><li><span><a href=\"#5.1.2-Extract-Jacks-Queen-and-King-to-add-it-to-mnist\" data-toc-modified-id=\"5.1.2-Extract-Jacks-Queen-and-King-to-add-it-to-mnist-5.1.2\">5.1.2 Extract Jacks Queen and King to add it to mnist</a></span></li></ul></li><li><span><a href=\"#5.2-Mnist-neural-network-training\" data-toc-modified-id=\"5.2-Mnist-neural-network-training-5.2\">5.2 Mnist neural network training</a></span></li><li><span><a href=\"#5.3-NN-performance-assessment-on-game-data.\" data-toc-modified-id=\"5.3-NN-performance-assessment-on-game-data.-5.3\">5.3 NN performance assessment on game data.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR][iapr]: Project\n",
    "\n",
    "\n",
    "**Group ID:** xx\n",
    "\n",
    "**Author 1 (sciper):** Student Name 1 (xxxxx)  \n",
    "**Author 2 (sciper):** Student Name 2 (xxxxx)   \n",
    "**Author 3 (sciper):** Student Name 3 (xxxxx)   \n",
    "\n",
    "**Release date:** 07.05.2021  \n",
    "**Due date:** 03.06.2021 (23h59)\n",
    "\n",
    "\n",
    "## Important notes\n",
    "\n",
    "The lab assignments are designed to teach practical implementation of the topics presented during class as well as preparation for the final project, which is a practical project which ties together the topics of the course. \n",
    "\n",
    "As such, in the lab assignments/final project, unless otherwise specified, you may, if you choose, use external functions from image processing/ML libraries like opencv and sklearn as long as there is sufficient explanation in the lab report. For example, you do not need to implement your own edge detector, etc.\n",
    "\n",
    "**! Before handling back the notebook !** rerun the notebook from scratch `Kernel` > `Restart & Run All`\n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Introduction\n",
    "\n",
    "An anonymous researcher that we will name Lann Yecun is convinced that the MNIST dataset still has great potential. He decides to create a playing card game based on MNIST digits and different figures. The game uses a standard 52 card deck which is composed of four French suits/colours: clubs (&#9827;), diamonds (&#9830;), hearts (&#9829;) and spades (&#9824;). Each suit includes 10 digit cards (from 0 to 9) and 3 figures (Jack-J, Queen-Q, and King-K). Here is an example of the 13 spade cards with their name.\n",
    "\n",
    "\n",
    "<img src=\"media/example_cards.png\">\n",
    "\n",
    "\n",
    "We can find the same arrangement of cards for the clubs, diamonds, and hearts. \n",
    "\n",
    "## 1. Rules\n",
    "\n",
    "\n",
    "### 1.1 Standard\n",
    "\n",
    "The rules are based on the simple battle card game. The goal of the game is to win as many points as possible. Each turn, the 4 players play a card in front of them. As displayed in the example below. The rules are the following:\n",
    "\n",
    "- The cards are ranked in the following order : **0 < 1 < 2 < 3 < 4 < 5 < 6 < 7 < 8 < 9 < J < Q < K**.\n",
    "- The player with the highest-ranked card wins the round and obtains **1 point**. \n",
    "- If the highest-ranked card is the same for multiple players we call it a draw and all winners get **1 points**. \n",
    "- In this configuration, we **do not** take into account the suits. The game only rely on the card ranks. \n",
    "- The game lasts 13 rounds. After the last round, the winner is the player that has the largest number of points. \n",
    "- In the example below Player 1 wins the round with his Queen ( 0 < 8 < J < **Q**).\n",
    "\n",
    "If two or more players have the same number of points they share the victory.\n",
    "\n",
    "### 1.2 Advanced\n",
    "\n",
    "The advanced rules take into account the suits. \n",
    "\n",
    "- At the beginning of **each round** a random player is designated as the **dealer**. The dealer places a green token with the letter *D* next to him (player 1 in the example below).\n",
    "- Only the cards that belong to the same suit as the one of the dealer are considered valid. In the example below, only Player 4 is competing with Player 1 as spade was selected by the dealer (e.i., Player 1). Player 2 and 3 are out for this round. Player 1 wins the round and **1 point** with the Queen ( 0&#9824; < **Q&#9824;**).\n",
    "- There cannot be any draw between the players as they are not any card duplicates.\n",
    "- We use the same system as the standard method to count the points.\n",
    "\n",
    "\n",
    "<img src=\"media/example_round.jpg\">\n",
    "\n",
    "\n",
    "### 1.3 Notes\n",
    "\n",
    "- The orientation of the card is linked to the position of the player around the table. For instance, to read the card of the 3rd player you will have to rotate it by 180Â°.\n",
    "- The **digits** always **face** the players around the table. The figures can have random orientations.\n",
    "- Player 1 **always** seats south of the table. The players are **always** ordered counter-clockwise as in the example. \n",
    "- The dealers can change between the rounds and games.\n",
    "- Some cards **might** apear multiple times per game.\n",
    "- Pictures are always taken from rougthly the same altitude.\n",
    "- The digits from the training set **would not** be the same as the one of the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data\n",
    "\n",
    "You will be given the images of 7 games that were played ([download link](https://drive.google.com/drive/folders/1fEy27wnJsUJPRsEEomzoAtP56s-7HFtk?usp=sharing)). The data are composed of:\n",
    "   - 7 folder named after the games (game1 to game7).\n",
    "   - Each game includes 13 ordered images (1st to 13th round).\n",
    "   - Each game includes a csv file with the ground truth of the game. The first row list the players (P1 to P4) as well as the dealer (D). The following rows represent the rounds (1 to 13). We represent the card played with 2 character as $AB$ where $A \\in [0-9, J, Q, K]$ is the rank of the card and $B \\in [C, D, H, S]$ is the suit. For example, QS means \"(Q)ueen of (S)pade\" and 0D means \"(0) of (D)iamond\". The dealer is represented by the ID of the player (e.g. P1 -> 1).\n",
    "   \n",
    "You are free to use external datasets such as the original MNIST train set that you used in lab 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Your Tasks\n",
    "\n",
    "Your task is to ready yourself for the final evaluation. The day of the exam we will give you a new folder with a new game. ! The digits on the cards **differ** from the one of the traning set. When given a new data folder with 13 images your should be able to:\n",
    "\n",
    "**Task 0**\n",
    "   - Plot an overlay for each round image that shows your detections and classification. You can for example plot bounding boxes around the cards/dealer token and add a text overlay with the name of the classes.\n",
    "\n",
    "**Task 1**\n",
    "   - (a) Predict the **rank** of the card played by each player at each round (Standard rules).\n",
    "   - (b) Predict the **number of points** of each player according to **Standard** rules\n",
    " \n",
    "**Task 2**\n",
    "   - (a) Detect which player is the selected **dealer** for each round.\n",
    "   - (b) Predict the **rank** and the **suit** of the card played by each player at each round (Advanced rules).\n",
    "   - (c) Predict the **number of points** of each player according to **Advanced** rules\n",
    "\n",
    "---\n",
    "\n",
    "**Before the exam (until 03.06.21 at 23h59)**\n",
    "   - Create a zipped folder named **group_xx.zip** that you uplaod on moodel (xx being your group number).\n",
    "   - Include a **runnable** code (Jupyter Notebook and external files) and your presentation in the zip folder.\n",
    "   \n",
    "**The day of the exam (04.06.21)**\n",
    "   - You will be given a **new folder** with 13 images (rounds) and but **no ground truth** (csv file).\n",
    "   - We will ask you to run your pipeline in **realtime** and to send us your prediction of task 1 and 2 that you obtain with the function **print_results**. \n",
    "   - On our side we will compute the perfomance of your classification algorithm. \n",
    "   - To evaluate your method we will use the **evaluate_game** function presented below. To understant how the provided functions work please read the documentation of the functions in **utils.py**.\n",
    "   - **Please make sure your function returns the proper data format to avoid points penalty the day of the exam**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1 Example Final results\n",
    "\n",
    "Example of output you **should** provide the day of the final exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T12:32:24.798128Z",
     "start_time": "2021-05-19T12:32:24.762223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cards played were:\n",
      "[\n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "['0D', '0D', '0D', '0D'], \n",
      "]\n",
      "Players designated as dealer: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Players points (standard): [0, 0, 0, 13]\n",
      "Players points (advanced): [0, 0, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "from utils import print_results\n",
    "import numpy as np\n",
    "\n",
    "# Creates dummy predictions (toy exmaple)\n",
    "pred_rank = np.array([\"0D\"]*4*13).reshape((13, 4)) # Everyone played the \"0 of spade\".\n",
    "pred_dealer = [1]*13                # List of players selected as dealer for each round\n",
    "pred_pts_stand = [0,0,0,13]         # Player 4 won 13 points with standard rules.\n",
    "pred_pts_advan = [0,0,8,7]          # Player 3 and 4 won 8 and 7 points with adv, rules respectively.\n",
    "\n",
    "print_results(\n",
    "    rank_colour=pred_rank, \n",
    "    dealer=pred_dealer, \n",
    "    pts_standard=pred_pts_stand,\n",
    "    pts_advanced=pred_pts_advan,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2 Example Accuracy\n",
    "\n",
    "Example of code you can use to validate the performance of your model. Be careful the day of the exam you will not have access to the ground truth of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model accuracy is: Standard=0.077, Advanced=0.019\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluate_game\n",
    "import pandas as pd\n",
    "#! You will need pandas libary to run the example. Please install the package using pip or conda commands !\n",
    "\n",
    "# Load ground truth from game 1\n",
    "cgt = pd.read_csv('./Data/game1/game1.csv', index_col=0)\n",
    "cgt_rank = cgt[['P1', 'P2', 'P3', 'P4']].values\n",
    "\n",
    "# Compute accuracy of prediction\n",
    "acc_standard = evaluate_game(pred_rank, cgt_rank, mode_advanced=False)\n",
    "acc_advanced = evaluate_game(pred_rank, cgt_rank, mode_advanced=True)\n",
    "print(\"Your model accuracy is: Standard={:.3f}, Advanced={:.3f}\".format(acc_standard, acc_advanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Our implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:40:21.961026Z",
     "start_time": "2021-06-02T16:40:20.050107Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from skimage.draw import polygon\n",
    "import tarfile\n",
    "import os\n",
    "import glob\n",
    "from skimage import color\n",
    "from skimage import measure\n",
    "import imutils\n",
    "import re\n",
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:40:21.976982Z",
     "start_time": "2021-06-02T16:40:21.964979Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load game number i\n",
    "def load_images(i):\n",
    "\n",
    "    data_base_path = os.path.join(os.pardir, 'Data')\n",
    "    data_folders = ['./Data/game'+ str(i) + '/' for i in range(1,8)]\n",
    "\n",
    "\n",
    "    files = [glob.glob1('./Data/game'+ str(i) +'/','*.jpg') for i in range(1,8)]\n",
    "\n",
    "    # Sort files according to the digits included in the filename\n",
    "    files = sorted(files[i], key=lambda x:float(re.findall(\"(\\d+)\",x)[0]))\n",
    "    files = [data_folders[i] + t for t in files]\n",
    "\n",
    "    game = [cv2.cvtColor(cv2.imread(file, ), cv2.COLOR_BGR2RGB) for file in files]\n",
    "    #game_gray = [cv2.imread(file, 0) for file in glob.glob(data_folders[1])]\n",
    "\n",
    "    #fig, axes = plt.subplots(1, 4, figsize = (13,3))\n",
    "\n",
    "    #for ax,i in zip(axes, range(4)):\n",
    "    #    ax.imshow(game[i])\n",
    "    #    ax.axis('off')\n",
    "        \n",
    "    return game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Card and dealer localisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Dealer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the dealer, we will find the letter D on the image. \n",
    "We will check the 20 largest contours found on the image and we will compute the perimeter and the area. If both are close to an expected value, we assume that this contour correspond to the dealer. We then compute the mean position of this contour to know which player is the dealer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:40:22.007872Z",
     "start_time": "2021-06-02T16:40:21.980937Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function will compute the number of pixel inside the contour using the polygon function. We use this function to find the \n",
    "# letter D\n",
    "def find_area(contour,im):\n",
    "    D=False\n",
    "    low_tresh=64000      # threshold to check if it is the contour corresponding to D\n",
    "    high_tresh=75000\n",
    "    Dshape=np.zeros((im.shape[0], im.shape[1]), 'uint8')\n",
    "    rr_z, cc_z = polygon(contour[:,0], contour[:,1], Dshape.shape) # polygon function that allow us to get all the points inside the contours\n",
    "    if (len(rr_z)>low_tresh) & (len(rr_z)<high_tresh): # check if the area is between two treshold\n",
    "        D=True\n",
    "    return D  # give as output True (letter D) or False (other contour)\n",
    "\n",
    "# Once we found the contour corresponding to the letter D, we find the dealer between the player by finding the computing the\n",
    "#distance between the letter D and the players \n",
    "def find_dealer(contour):\n",
    "    \n",
    "    left=[2300,740]          #[2211,742]\n",
    "    up= [745, 1728]           #[745,1824]\n",
    "    right= [2300 ,2716]       #[2129,2831]\n",
    "    down= [3462,1728]         #[3462,1709]\n",
    "    \n",
    "    mean_x=np.mean(contour[:,1])\n",
    "    mean_y=np.mean(contour[:,0])\n",
    "    \n",
    "    dist=[]\n",
    "    \n",
    "    dist.append(math.dist(down,[mean_y,mean_x]))\n",
    "    dist.append(math.dist(right,[mean_y,mean_x]))\n",
    "    dist.append(math.dist(up,[mean_y,mean_x])) \n",
    "    dist.append(math.dist(left,[mean_y,mean_x]))\n",
    "   \n",
    "    dealer=np.argmin(dist)+1\n",
    "    return dealer # Give as output the player how is the dealer\n",
    "\n",
    "# Main function to check if it is a D. Will first compute the length of the contour to check if it is similar to the length of \n",
    "# the contour of the expected letter D and then will call find area to add a second criteria to be sure that it correspond to \n",
    "# the letter D. \n",
    "\n",
    "# Once we found the correct contour, we call find_dealer to find the player who is the dealer\n",
    "def check_D(contours,im):\n",
    "    low_tresh=1000\n",
    "    high_tresh=1850\n",
    "    y,x=im.shape\n",
    "    index=False\n",
    "    Dshape=[0,0]\n",
    "    dealer=1  # if we don't find the D, the contour will be equl to [0,0] and the dealer will be player 1\n",
    "    for i in range(30):\n",
    "        if (len(contours[i])>low_tresh) & (len(contours[i])<high_tresh):\n",
    "            test=find_area(contours[i],im)\n",
    "            if test==True:\n",
    "                Dshape=contours[i]\n",
    "\n",
    "                dealer=find_dealer(contours[i])\n",
    "    return Dshape,dealer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the cards, we will compute the contours on the images and then check the 20 largest contours to see if they are similar to the one expected for a card. We also check where this contours is on the image to find the player who played the cards. \n",
    "Once we found the 4 cards, we will crop them and rotate them so that we have for each image 4 cards oriented the same way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:40:22.053743Z",
     "start_time": "2021-06-02T16:40:22.010856Z"
    }
   },
   "outputs": [],
   "source": [
    "#Once we found a contour corresponding to a card, we will check if it correspond to up, down, left or right and we will add \n",
    "# them to a dictionnary (Using our contours, it is possible to find different contours for a same card)\n",
    "# we will later on select only the smallest contour (the one corresponding to the interior of the card)\n",
    "def find_card(contour,xmean,ymean,cards):\n",
    "    # check for which card : \n",
    "    left=[2300,740]          #[2211,742]\n",
    "    up= [745, 1728]           #[745,1824]\n",
    "    right= [2300 ,2716]       #[2129,2831]\n",
    "    down= [3462,1728]         #[3462,1709]\n",
    "    category=0\n",
    "    if (math.dist(left,[ymean,xmean])<600):\n",
    "        cards['left'].append(contour)\n",
    "\n",
    "        category=1\n",
    "    if (math.dist(up,[ymean,xmean])<600):\n",
    "        cards['up'].append(contour)\n",
    "\n",
    "    if (math.dist(right,[ymean,xmean])<600):\n",
    "        cards['right'].append(contour)\n",
    "\n",
    "    if (math.dist(down ,[ymean,xmean])<600):\n",
    "        cards['down'].append(contour)\n",
    "\n",
    "    \n",
    "    return cards # return as output a dictionnary with the contours already found corresponding to a card\n",
    "    \n",
    "# main function to check if the contour correspond to a card. We will first compute the size in x and y of the contour\n",
    "# to see if it is similar to the one for a card. If it is the case, we call find_card() to check from which player it is the \n",
    "# cards. \n",
    "def check_card(contour,cards):\n",
    "    xmax=np.max(contour[:,1])\n",
    "    xmin=np.min(contour[:,1])\n",
    "    ymax=np.max(contour[:,0])\n",
    "    ymin=np.min(contour[:,0])\n",
    "    \n",
    "    h=np.max([xmax-xmin,ymax-ymin])\n",
    "    w=np.min([xmax-xmin,ymax-ymin])\n",
    "    mean_x=(xmax+xmin)/2\n",
    "    mean_y=(ymax+ymin)/2\n",
    "    #print('mean_x',mean_x)\n",
    "    #print('mean_y',mean_y)\n",
    "    \n",
    "    # treshold for high and width of the cards :\n",
    "    tr_hH_card=900\n",
    "    tr_hL_card=630\n",
    "    tr_wH_card=640\n",
    "    tr_wL_card=420\n",
    "    \n",
    "\n",
    "    if (tr_hL_card<h) &(h<tr_hH_card) & (tr_wL_card<w) & (w<tr_wH_card):\n",
    "            cards=find_card(contour,mean_x,mean_y,cards)\n",
    "\n",
    "    return cards # return as output a dictionnary with the contours for each cards\n",
    "\n",
    "# To rotate the card\n",
    "def crop_with_ctr(contours, imgRGB, imgray, plot = False):\n",
    "    # goal of this algorithm is to get from the contours the image of the card \n",
    "    cardsRGB = []  \n",
    "    cardsgray=[]\n",
    "    for ctr in contours:\n",
    "        \n",
    "        if len(ctr)!=2:\n",
    "            xmin = max(int(min(ctr[:,1])),30) # add this condition min max to avoid problem when doing rotation of the image\n",
    "            xmax = min(int(max(ctr[:,1])),imgray.shape[1]-30)\n",
    "            ymin = max(int(min(ctr[:,0])),30)\n",
    "            ymax = min(int(max(ctr[:,0])),imgray.shape[0]-30)\n",
    "\n",
    "            cardsRGB.append(imgRGB[ymin-5:ymax+5, xmin-5:xmax+5,:])   # cards in colors \n",
    "            cardsgray.append(imgray[ymin-5:ymax+5, xmin-5:xmax+5]) \n",
    "        else:\n",
    "            cardsRGB.append(imgRGB[1000-5:1600+5, 1000-5:1800+5,:])   # cards in colors \n",
    "            cardsgray.append(imgray[1000-5:1600+5, 1000-5:1800+5]) \n",
    "    if plot :   \n",
    "        _,axes = plt.subplots(1,4,figsize =(13,3))\n",
    "        for card,ax in zip(cardsRGB,axes):\n",
    "            \n",
    "            ax.imshow(card)  \n",
    "    return cardsRGB,cardsgray # get the 4 images in gray or in RGB\n",
    "\n",
    "def rotate_card(gray_card,cards, plot=False):\n",
    "    # rotate the card to get all of them in the same order \n",
    "    \n",
    "    for i in range(len(gray_card)):\n",
    "        angle=i*90\n",
    "        gray_card[i] = imutils.rotate_bound(gray_card[i], angle =angle)\n",
    "        cards [i] = imutils.rotate_bound(cards[i], angle = angle)\n",
    "        \n",
    "    if plot :   \n",
    "        _,axes = plt.subplots(1,4,figsize =(13,3))\n",
    "        for card,ax in zip(cards,axes):\n",
    "            ax.imshow(card,'gray')\n",
    "    return gray_card,cards # get the 4 images in gray or in RGB with the same orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Image preprocessing\n",
    "\n",
    "Output: 4 set of images containing mnist numbers + card color + card symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the number on the image we will compute the contours of the number in the middle of the cards. We will then select a square of size (340,340) centered at the middle of the contour. We will then resize this image to get an image of size (28,28) that we will give to our deep learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:40:22.084658Z",
     "start_time": "2021-06-02T16:40:22.057731Z"
    }
   },
   "outputs": [],
   "source": [
    "# The goal of this function is to get as output an image of the number with a size equal to (28,28) that we will give later to our \n",
    "# deep learning model\n",
    "def find_number(contours,img,plot=False):\n",
    "    \n",
    "    # method : crop a little so that we are sure that the first contour is the number, find the contour of the number\n",
    "    #            extend the image so that it is a square capturing all the image, reshape it so that the output is 28*28 ; \n",
    "   \n",
    "   \n",
    "    if len(img[1,:])*len(img[:,1])!= 494100:  # if we find the card\n",
    "        #method 2\n",
    "        xmin=50\n",
    "        xmax=400\n",
    "        ymin=150\n",
    "        ymax=550\n",
    "\n",
    "        center_image=[]\n",
    "        center_image.append(img[ymin:ymax,xmin:xmax])\n",
    "\n",
    "        contours = measure.find_contours(center_image[0], level = 100)\n",
    "        contours = sorted(contours, key=len, reverse=True)    # sort them so that we have the largest one at index 0\n",
    "\n",
    "        if plot==True:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "            ax.imshow(center_image[0], cmap='gray')\n",
    "            ax.plot(contours[0][:,1], contours[0][:,0], linewidth=1,c='r')\n",
    "\n",
    "        xmean=int(np.mean(contours[0][:,1]))+xmin # find the mean value of the contour\n",
    "        ymean=int(np.mean(contours[0][:,0]))+ymin  \n",
    "        \n",
    "        tresh_size=170 # size of the square/2\n",
    "\n",
    "        # crop the image around the number :      \n",
    "        y_down=max(ymean-tresh_size,0)\n",
    "        if y_down==0:\n",
    "            y_up=2*tresh_size\n",
    "        else:\n",
    "            y_up=ymean+tresh_size\n",
    "        x_down=max(xmean-tresh_size,0)\n",
    "        if x_down==0:\n",
    "            x_up=2*tresh_size\n",
    "        else:\n",
    "            x_up=xmean+tresh_size\n",
    "        number_im=img[y_down:y_up,x_down:x_up]\n",
    "        \n",
    "        \n",
    "        # resize the image to get 28*28 : \n",
    "        number_im_resize=cv2.resize(number_im, (28,28), interpolation = cv2.INTER_AREA) # to get it in the correct size \n",
    "        if plot==True:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "            ax.imshow(number_im_resize, cmap='gray')\n",
    "    \n",
    "    \n",
    "    else:  # if we didn't find the image, just give a portion of the image\n",
    "         number_im_resize= img[0:28,0:28]\n",
    "    return number_im_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Neural Network for mnist numbers\n",
    "\n",
    "see [annex 5.2](#5.2-Mnist-neural-network-training) for model training\n",
    "\n",
    "Ouput: list of numbers for recognised mnist numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:40:23.063919Z",
     "start_time": "2021-06-02T16:40:22.236300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Creating Neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super().__init__()\n",
    "        self.nb_hidden = nb_hidden\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 13)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d( 1, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(64 * 3*3, 13)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Pattern Recognition for card symbols\n",
    "Output: list of words for recognised symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this function is to find the symbol on the image. To do that we will compute the contours of those symbols find the color by looking at the mean value in Red inside the contours and then use the fourier descriptors to find the correct symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:40:23.110732Z",
     "start_time": "2021-06-02T16:40:23.067847Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_symbol(contours,imRGB):\n",
    "    \n",
    "    #First we exctract the contours corresponding to the symbols (pique coeurs ...): \n",
    "    \n",
    "    tresh_up_left=[100,50]\n",
    "    tresh_down_right=[600,450]\n",
    "    tresh_dist=130\n",
    "    thresh_w=80\n",
    "    thresh_h=100\n",
    "    symbol1=[]\n",
    "    symbol2=[]\n",
    "    range_i=min(10,len(contours))\n",
    "    for i in range(range_i):\n",
    "        if len(contours[i])!=2:\n",
    "            x_mean=np.mean(contours[i][:,1])\n",
    "            y_mean=np.mean(contours[i][:,0])\n",
    "\n",
    "            # first condition to see if the contour correspond to a symbol (if close to top left corner)\n",
    "            if math.dist(tresh_up_left,[y_mean,x_mean])<tresh_dist:\n",
    "                xmax=np.max(contours[i][:,1])\n",
    "                xmin=np.min(contours[i][:,1])\n",
    "                ymax=np.max(contours[i][:,0])\n",
    "                ymin=np.min(contours[i][:,0])\n",
    "                # second condition to check if the contour correspond to a symbol (similar dimension)\n",
    "                if (abs((xmax-xmin)-thresh_w)<30) & (abs((ymax-ymin)-thresh_h)<30):\n",
    "                    symbol1=contours[i]\n",
    "\n",
    "\n",
    "            # first condition to see if the contour correspond to a symbol (if close to bottom right corner)\n",
    "            if math.dist(tresh_down_right,[y_mean,x_mean])<tresh_dist:\n",
    "                xmax=np.max(contours[i][:,1])\n",
    "                xmin=np.min(contours[i][:,1])\n",
    "                ymax=np.max(contours[i][:,0])\n",
    "                ymin=np.min(contours[i][:,0])\n",
    "                # second condition to check if the contour correspond to a symbol (similar dimension)\n",
    "                if (abs((xmax-xmin)-thresh_w)<50) & (abs((ymax-ymin)-thresh_h)<50):\n",
    "                    symbol2=contours[i]\n",
    "\n",
    "    \n",
    "    #second we find the symbol :\n",
    "    \n",
    "    # find if red or black: \n",
    "    \n",
    "    # sometimes it don't detect one of the symbol so we select the one that is not empty bottom right or top left \n",
    "    if len(symbol1)!=0:\n",
    "        symbolctr=symbol1\n",
    "    elif len(symbol2)!=0 :\n",
    "        symbolctr=symbol2\n",
    "    else:\n",
    "        symbolctr=[0]\n",
    "        symbol='S'\n",
    "        \n",
    "    if len(symbolctr)!=1:\n",
    "        \n",
    "        rr_z, cc_z = polygon(symbolctr[:,0], symbolctr[:,1]) # polygon to compute all the point inside the contours : \n",
    "\n",
    "\n",
    "        meanR=imRGB[rr_z,cc_z,0].mean() \n",
    "\n",
    "        # Use meanR to check if it is red or black\n",
    "        thresh_color=80\n",
    "\n",
    "        if meanR>thresh_color:\n",
    "            color_image='red'\n",
    "        else:\n",
    "            color_image='black'\n",
    "    \n",
    "        # USE COMPACITY : \n",
    "        #symbol=compacity(symbolctr,rr_z, color_image) # get poor results \n",
    "        \n",
    "        #Use fourrier descriptor : \n",
    "        symbol=compute_fourrier_descriptor(symbolctr,color_image, fourrier_component = [1,2,5]) # get better results \n",
    "        \n",
    "    return symbol   \n",
    "\n",
    "\n",
    "def compacity(symbolctr,rr_z,color_image):\n",
    "\n",
    "        # find the symbol by computing the compacity :\n",
    "\n",
    "        P_coeur=33\n",
    "        P_carreaux=37   # pas ouf la distinction avec coeur \n",
    "        P_pique=46 \n",
    "        P_trefle=61\n",
    "\n",
    "        P=(len(symbolctr)**2)/len(rr_z)\n",
    "   \n",
    "    \n",
    "        if color_image=='red':\n",
    "            sym=np.argmin([abs(P_coeur-P),abs(P_carreaux-P)])\n",
    "            if sym==0:\n",
    "                symbol='H'\n",
    "            else:\n",
    "                symbol='D'\n",
    "\n",
    "        if color_image=='black':\n",
    "            sym=np.argmin([abs(P_pique-P),abs(P_trefle-P)])\n",
    "            if sym==0:\n",
    "                symbol='S'\n",
    "            else:\n",
    "                symbol='C'\n",
    "        return symbol\n",
    "                \n",
    "# Fourier descriptor : \n",
    "\n",
    "def compute_fourrier_descriptor(contour_pts,color_image, fourrier_component = [1,2,5]):\n",
    "    fourrier_descriptors = []\n",
    "\n",
    "    for i in fourrier_component:\n",
    "    \n",
    "        # For each contour point we add add contribtuion\n",
    "        fourrier_desc = complex(0,0)\n",
    "        for j in range(0,len(contour_pts)):\n",
    "            fourrier_desc += complex(contour_pts[j,0],contour_pts[j,1]) * cmath.exp(- complex(0,1) * 2 * math.pi * j*i/len(contour_pts))\n",
    "\n",
    "        # Transform the number to polar mapping to extract only amplitude (invariant to amplitude and starting point)\n",
    "        fourrier_desc = cmath.polar(fourrier_desc)\n",
    "        fourrier_descriptors.append(fourrier_desc[0])\n",
    "    F_descriptors=[]\n",
    "    F_descriptors.append(fourrier_descriptors[1]/fourrier_descriptors[0])\n",
    "    F_descriptors.append(fourrier_descriptors[2]/fourrier_descriptors[0])\n",
    "    \n",
    "    # use two fourier descriptors to find the shape [A2 and A5] both of them are divide by A1 so that they are invariant to \n",
    "    # rotation and scaling\n",
    "    \n",
    "    S_val= [0.22, 0.11]\n",
    "    C_val=[0.07, 0.20]\n",
    "    \n",
    "    H_val= [0.080, 0.032]\n",
    "    D_val=[0.004, 0.05]\n",
    "    \n",
    "    dist=[]\n",
    "    \n",
    "\n",
    "    if color_image=='red':\n",
    "        dist.append(math.dist(F_descriptors,H_val)) # compute the distance to the expected value for the shape \n",
    "        dist.append(math.dist(F_descriptors,D_val))\n",
    "        idx=np.argmin(dist) # check from which point it is the closest : \n",
    "        if idx==0:\n",
    "            symbol='H'\n",
    "        else:\n",
    "            symbol='D'\n",
    "\n",
    "    if color_image=='black':\n",
    "        dist.append(math.dist(F_descriptors,S_val))\n",
    "        dist.append(math.dist(F_descriptors,C_val))\n",
    "        idx=np.argmin(dist)\n",
    "        if idx==0:\n",
    "            symbol='S'\n",
    "        else:\n",
    "            symbol='C'\n",
    "    return symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Creating an overlay \n",
    "\n",
    "Outputs: round image with added overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Points with standard rule\n",
    "\n",
    "Outputs: list of points of each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:40:23.126725Z",
     "start_time": "2021-06-02T16:40:23.114722Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_std_point(numbers):\n",
    "    points = [0,0,0,0]\n",
    "    maxs = np.amax(numbers,axis=1)\n",
    "    for i in range(0,len(numbers)):\n",
    "        for j in np.where(numbers[i,:] == maxs[i])[0]:\n",
    "            points[j] += 1\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Points with advanced rule\n",
    "\n",
    "Outputs: list of points of each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:40:23.345907Z",
     "start_time": "2021-06-02T16:40:23.328954Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_adv_points(numbers,suits,dealer):\n",
    "    for i in range(0,len(numbers)):\n",
    "        for j in np.where(np.array(final_prediction[i])!=final_prediction[i][dealer[i]-1])[0]:\n",
    "            numbers[i,j]=-1\n",
    "    points = get_std_point(numbers)\n",
    "    return points\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Pipeline + Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:41:50.473245Z",
     "start_time": "2021-06-02T16:40:24.464093Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-9f5a468f7ff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthresh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# treshold on the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mcontours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_contours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# find the contours\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mcontours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# sort them so that we have the largest one at index 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\measure\\_find_contours.py\u001b[0m in \u001b[0;36mfind_contours\u001b[1;34m(array, level, fully_connected, positive_orientation, mask)\u001b[0m\n\u001b[0;32m    135\u001b[0m     segments = _get_contour_segments(array.astype(np.double), float(level),\n\u001b[0;32m    136\u001b[0m                                      fully_connected == 'high', mask=mask)\n\u001b[1;32m--> 137\u001b[1;33m     \u001b[0mcontours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_assemble_contours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpositive_orientation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'high'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mcontours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\measure\\_find_contours.py\u001b[0m in \u001b[0;36m_assemble_contours\u001b[1;34m(segments)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mends\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_point\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontour\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\measure\\_find_contours.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mends\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_point\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontour\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Try to find the contours of the cards :  \n",
    "\n",
    "# Add your implementation and discussion\n",
    "from skimage import measure\n",
    "import numpy as np\n",
    "\n",
    "game_number = 5 # choose the game  \n",
    "game = load_images(game_number-1)\n",
    "\n",
    "dealer=[]            # array with the player dealer at each row\n",
    "\n",
    "final_prediction=[]  # list where we keep the prediction for the symbol on each card \n",
    "final_number=[]      # list where we keep images of size (28,28) of the number on each image that we will give to our model\n",
    "\n",
    "\n",
    "cards_games=[]       # list where we keep the contours on each card \n",
    "dealer_games=[]      # list where we keep the contour of the D on the dealer coin  \n",
    "for j in range(13):\n",
    "    \n",
    "    cards = {'left':[],'up':[],'right':[],'down':[]} # initialize a dictionnary where we will add the contours corresponding to \n",
    "    # each cards\n",
    "    \n",
    "    img=cv2.cvtColor(game[j],cv2.COLOR_RGB2GRAY)\n",
    "    n,thresh = cv2.threshold(img,150, 255, cv2.THRESH_BINARY) # treshold on the image\n",
    "\n",
    "    contours = measure.find_contours(thresh, level = 100) # find the contours\n",
    "    contours = sorted(contours, key=len, reverse=True)    # sort them so that we have the largest one at index 0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(20): # check the 20 first contours to extract the cards contours\n",
    "        cards=check_card(contours[i],cards)\n",
    "    cards_final=[] # list with only one contour for each card (take the smallest)\n",
    "    \n",
    "    # add a condition to be sure that we found a contour for the card. If not, give instead [0,0]\n",
    "    if len(cards['down'])!=0:\n",
    "        cards_final.append(cards['down'][-1])\n",
    "    else:\n",
    "        cards_final.append([0,0])\n",
    "    if len(cards['right'])!=0:\n",
    "        cards_final.append(cards['right'][-1])\n",
    "    else:\n",
    "        cards_final.append([0,0])\n",
    "        \n",
    "    if len(cards['up'])!=0:\n",
    "        cards_final.append(cards['up'][-1])\n",
    "    else:\n",
    "        cards_final.append([0,0])\n",
    "    if len(cards['left'])!=0:\n",
    "        cards_final.append(cards['left'][-1])\n",
    "    else:\n",
    "        cards_final.append([0,0])\n",
    "    \n",
    "    contour_D,new_dealer=check_D(contours,thresh) # compute the contour of the letter D and the dealer \n",
    "    dealer.append(new_dealer)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # GET THE FOUR CARDS IN THE SAME ORIENTATION : \n",
    "    cardsRGB, cardsgray = crop_with_ctr(cards_final, game[j], img, False)\n",
    "    cardsgray, cardsRGB = rotate_card(cardsgray,cardsRGB, plot=False) # rotate the cards with the good orientation \n",
    "    \n",
    "    # EXTRACT THE FEATURES : \n",
    "    number_symbols=[]\n",
    "    number_images=[]\n",
    "\n",
    "    for i in range(4):\n",
    "\n",
    "        n,imthresh = cv2.threshold(cardsgray[i],145, 255, cv2.THRESH_BINARY)\n",
    "        # find again the contours to get the number and the symbol : \n",
    "        contours = measure.find_contours(imthresh, level = 100) # find the contours\n",
    "        contours = sorted(contours, key=len, reverse=True)  \n",
    "\n",
    "        number_symbol=find_symbol(contours,cardsRGB[i])  \n",
    "        number_symbols.append(number_symbol)\n",
    "        number_image=find_number(contours,imthresh)\n",
    "        number_images.append(number_image)\n",
    "\n",
    "    # ADD THE DIFFERENT PREDICTIONS AND CONTOURS FOUND FOR THE ROW :\n",
    "    final_prediction.append(number_symbols)\n",
    "    final_number.append(number_images)\n",
    "    cards_games.append(cards_final)\n",
    "    dealer_games.append(contour_D)  \n",
    "    \n",
    "\n",
    "    \n",
    "a = torch.tensor(np.array(final_number)).view(-1,28,28).unsqueeze(1).type(torch.FloatTensor)\n",
    "mu, std = a.mean(), a.std()\n",
    "a.sub_(mu).div_(std)\n",
    "\n",
    "# Loading previously trained model\n",
    "model = Net(200)\n",
    "model.load_state_dict(torch.load(f'./M23.5-Model-Net-I65000-E200-R0.pth'))\n",
    "model.eval()\n",
    "\n",
    "output = model(-a)\n",
    "_, predicted_numbers = output.max(1)\n",
    "predicted_numbers = np.array(predicted_numbers.view(13,-1))\n",
    "predicted_classes = np.where(predicted_numbers==10, 'J', predicted_numbers).astype(str)\n",
    "predicted_classes = np.where(predicted_classes=='11', 'Q', predicted_classes) \n",
    "predicted_classes = np.where(predicted_classes=='12', 'K', predicted_classes)\n",
    "predicted_classes = np.char.add(predicted_classes, np.array(final_prediction))\n",
    "\n",
    "# Plot our results\n",
    "# default position values\n",
    "pos = np.array([[1600,3300],[2500,2400],[2080,1134],[1030,2250]])\n",
    "off=500\n",
    "offset = np.array([[-off,0],[0,-off-100],[off,0],[0,off]])\n",
    "fig, axes = plt.subplots(13, 1, figsize=(100, 100))\n",
    "for ax,cards, dealer_ctr, im, pred in zip(axes, cards_games, dealer_games, game,predicted_classes):\n",
    "    \n",
    "    ax.imshow(im, cmap='gray')\n",
    "    for i in range(len(cards)):\n",
    "        if len(cards[i])!=2: # plot only if we have found a contour \n",
    "            ax.plot(cards[i][:,1], cards[i][:,0], linewidth=2,c='b')\n",
    "            y,x = np.mean(cards[i],axis=0)+offset[i]\n",
    "        else:\n",
    "            x,y = pos[i]\n",
    "            \n",
    "        ax.text(x,y,pred[i],weight='bold')\n",
    "        if len(dealer_ctr)!=2:   # plot only if we have found a dealer\n",
    "            ax.plot(dealer_ctr[:,1], dealer_ctr[:,0], linewidth=2,c='r')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:41:51.094088Z",
     "start_time": "2021-06-02T16:41:50.499175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME NUMBER  5 \n",
      "\n",
      "What we found :\n",
      "Player found as dealer :  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "\n",
      "\n",
      " Errors made on numbers :\n",
      " Truth-Result\n",
      "\u001b[92m J-J \u001b[0m,\u001b[92m 2-2 \u001b[0m,\u001b[91m 9-4 \u001b[0m,\u001b[92m 0-0 \u001b[0m\n",
      "\u001b[92m 2-2 \u001b[0m,\u001b[92m 3-3 \u001b[0m,\u001b[92m 7-7 \u001b[0m,\u001b[92m 6-6 \u001b[0m\n",
      "\u001b[92m 8-8 \u001b[0m,\u001b[92m 4-4 \u001b[0m,\u001b[92m J-J \u001b[0m,\u001b[92m J-J \u001b[0m\n",
      "\u001b[92m 4-4 \u001b[0m,\u001b[92m 6-6 \u001b[0m,\u001b[92m 3-3 \u001b[0m,\u001b[92m 5-5 \u001b[0m\n",
      "\u001b[92m 5-5 \u001b[0m,\u001b[92m K-K \u001b[0m,\u001b[92m 3-3 \u001b[0m,\u001b[92m K-K \u001b[0m\n",
      "\u001b[92m 6-6 \u001b[0m,\u001b[92m Q-Q \u001b[0m,\u001b[92m 6-6 \u001b[0m,\u001b[92m Q-Q \u001b[0m\n",
      "\u001b[92m 3-3 \u001b[0m,\u001b[92m K-K \u001b[0m,\u001b[92m 8-8 \u001b[0m,\u001b[92m K-K \u001b[0m\n",
      "\u001b[92m 5-5 \u001b[0m,\u001b[92m 1-1 \u001b[0m,\u001b[92m 5-5 \u001b[0m,\u001b[92m Q-Q \u001b[0m\n",
      "\u001b[92m K-K \u001b[0m,\u001b[92m 2-2 \u001b[0m,\u001b[92m 8-8 \u001b[0m,\u001b[92m 4-4 \u001b[0m\n",
      "\u001b[92m Q-Q \u001b[0m,\u001b[92m 3-3 \u001b[0m,\u001b[92m 4-4 \u001b[0m,\u001b[92m 2-2 \u001b[0m\n",
      "\u001b[92m 6-6 \u001b[0m,\u001b[92m J-J \u001b[0m,\u001b[92m 0-0 \u001b[0m,\u001b[92m 8-8 \u001b[0m\n",
      "\u001b[92m 9-9 \u001b[0m,\u001b[92m 7-7 \u001b[0m,\u001b[92m 0-0 \u001b[0m,\u001b[92m 1-1 \u001b[0m\n",
      "\u001b[92m 1-1 \u001b[0m,\u001b[92m 6-6 \u001b[0m,\u001b[92m 0-0 \u001b[0m,\u001b[92m 1-1 \u001b[0m\n",
      "\n",
      "\n",
      " Errors made on symbols :\n",
      " Truth-Result\n",
      "\u001b[92m H-H \u001b[0m,\u001b[92m S-S \u001b[0m,\u001b[92m C-C \u001b[0m,\u001b[92m C-C \u001b[0m\n",
      "\u001b[92m D-D \u001b[0m,\u001b[92m S-S \u001b[0m,\u001b[92m S-S \u001b[0m,\u001b[92m H-H \u001b[0m\n",
      "\u001b[92m D-D \u001b[0m,\u001b[92m C-C \u001b[0m,\u001b[92m S-S \u001b[0m,\u001b[92m D-D \u001b[0m\n",
      "\u001b[92m S-S \u001b[0m,\u001b[92m S-S \u001b[0m,\u001b[92m C-C \u001b[0m,\u001b[92m S-S \u001b[0m\n",
      "\u001b[92m C-C \u001b[0m,\u001b[92m C-C \u001b[0m,\u001b[92m H-H \u001b[0m,\u001b[92m H-H \u001b[0m\n",
      "\u001b[92m H-H \u001b[0m,\u001b[92m H-H \u001b[0m,\u001b[92m D-D \u001b[0m,\u001b[92m S-S \u001b[0m\n",
      "\u001b[92m H-H \u001b[0m,\u001b[92m H-H \u001b[0m,\u001b[92m S-S \u001b[0m,\u001b[92m S-S \u001b[0m\n",
      "\u001b[92m H-H \u001b[0m,\u001b[92m C-C \u001b[0m,\u001b[92m D-D \u001b[0m,\u001b[92m C-C \u001b[0m\n",
      "\u001b[92m D-D \u001b[0m,\u001b[92m H-H \u001b[0m,\u001b[92m H-H \u001b[0m,\u001b[92m H-H \u001b[0m\n",
      "\u001b[92m D-D \u001b[0m,\u001b[92m D-D \u001b[0m,\u001b[92m D-D \u001b[0m,\u001b[92m C-C \u001b[0m\n",
      "\u001b[92m S-S \u001b[0m,\u001b[92m C-C \u001b[0m,\u001b[92m S-S \u001b[0m,\u001b[92m C-C \u001b[0m\n",
      "\u001b[92m D-D \u001b[0m,\u001b[92m H-H \u001b[0m,\u001b[92m D-D \u001b[0m,\u001b[92m H-H \u001b[0m\n",
      "\u001b[92m D-D \u001b[0m,\u001b[92m C-C \u001b[0m,\u001b[92m H-H \u001b[0m,\u001b[92m S-S \u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Final accuracy\n",
      "Your model accuracy is: Standard=0.981, Advanced=0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"GAME NUMBER \",game_number,\"\\n\\nWhat we found :\\nPlayer found as dealer : \",dealer)\n",
    "t = np.char.add(predicted_classes, np.array(final_prediction))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "# Load ground truth from game i\n",
    "cgt = pd.read_csv('./Data/game'+ str(game_number) + '/game'+ str(game_number) + '.csv', index_col=0)\n",
    "cgt_rank = cgt[['P1', 'P2', 'P3', 'P4']].values\n",
    "\n",
    "\n",
    "print('\\n\\n Errors made on numbers :\\n Truth-Result')\n",
    "print('\\n'.join([','.join(row) for row in np.array([\"\\x1b[92m \" + a + \"-\"+b+ \" \\x1b[0m\" if (a==b) else \"\\x1b[91m \" + a + \"-\"+b+ \" \\x1b[0m\" for a,b in zip(np.array([v[0] for v in cgt_rank.flatten()]),np.array([v[0] for v in t.flatten()]))]).reshape(t.shape).tolist()]))\n",
    "\n",
    "print('\\n\\n Errors made on symbols :\\n Truth-Result')\n",
    "print('\\n'.join([','.join(row) for row in np.array([\"\\x1b[92m \" + a + \"-\"+b+ \" \\x1b[0m\" if (a==b) else \"\\x1b[91m \" + a + \"-\"+b+ \" \\x1b[0m\" for a,b in zip(np.array([v[1] for v in cgt_rank.flatten()]),np.array([v[1] for v in t.flatten()]))]).reshape(t.shape).tolist()]))\n",
    "\n",
    "\n",
    "\n",
    "# Compute accuracy of prediction\n",
    "from utils import evaluate_game\n",
    "acc_standard = evaluate_game(t, cgt_rank, mode_advanced=False)\n",
    "acc_advanced = evaluate_game(t, cgt_rank, mode_advanced=True)\n",
    "print(\"\\n\\n\\nFinal accuracy\\nYour model accuracy is: Standard={:.3f}, Advanced={:.3f}\".format(acc_standard, acc_advanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:41:51.109049Z",
     "start_time": "2021-06-02T16:41:51.097094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cards played were:\n",
      "[\n",
      "['JH', '2S', '4C', '0C'], \n",
      "['2D', '3S', '7S', '6H'], \n",
      "['8D', '4C', 'JS', 'JD'], \n",
      "['4S', '6S', '3C', '5S'], \n",
      "['5C', 'KC', '3H', 'KH'], \n",
      "['6H', 'QH', '6D', 'QS'], \n",
      "['3H', 'KH', '8S', 'KS'], \n",
      "['5H', '1C', '5D', 'QC'], \n",
      "['KD', '2H', '8H', '4H'], \n",
      "['QD', '3D', '4D', '2C'], \n",
      "['6S', 'JC', '0S', '8C'], \n",
      "['9D', '7H', '0D', '1H'], \n",
      "['1D', '6C', '0H', '1S'], \n",
      "]\n",
      "Players designated as dealer: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "Players points (standard): [4, 6, 2, 5]\n",
      "Players points (advanced): [0, 3, 2, 8]\n"
     ]
    }
   ],
   "source": [
    "from utils import print_results\n",
    "\n",
    "\n",
    "pred_pts_stand = get_std_point(predicted_numbers)        \n",
    "pred_pts_advan = get_adv_points(predicted_numbers,np.array(final_prediction),dealer)\n",
    "\n",
    "print_results(\n",
    "    rank_colour=predicted_classes,#, np.array(final_prediction)), np.char.add(\n",
    "    dealer=dealer, \n",
    "    pts_standard=pred_pts_stand,\n",
    "    pts_advanced=pred_pts_advan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['H', 'S', 'C', 'C'],\n",
       "       ['D', 'S', 'S', 'H'],\n",
       "       ['D', 'C', 'S', 'D'],\n",
       "       ['S', 'S', 'C', 'S'],\n",
       "       ['C', 'C', 'H', 'H'],\n",
       "       ['H', 'H', 'D', 'S'],\n",
       "       ['H', 'H', 'S', 'S'],\n",
       "       ['H', 'C', 'D', 'C'],\n",
       "       ['D', 'H', 'H', 'H'],\n",
       "       ['D', 'D', 'D', 'C'],\n",
       "       ['S', 'C', 'S', 'C'],\n",
       "       ['D', 'H', 'D', 'H'],\n",
       "       ['D', 'C', 'H', 'S']], dtype='<U1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(final_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Annexe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Extract game data\n",
    "\n",
    "#### 5.1.1 Extract all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:27:53.434939Z",
     "start_time": "2021-06-02T16:27:53.407017Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# CRITICAL : only main outputs\n",
    "# WARNING : main Outputs and secondary\n",
    "# DEBUG : full Outputs, and model loss\n",
    "logging.basicConfig(level=logging.WARNING, format='%(message)s')\n",
    "\n",
    "def extract_card_number():\n",
    "    \"\"\"\n",
    "    Extract all the numbers on all cards played (7 games, 13 rounds, 4 cards)\n",
    "    \n",
    "    OUTPUTS:\n",
    "        - list of all numbers\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    final_number=[]\n",
    "\n",
    "    for game_number in range(1,8):\n",
    "        game = load_images(game_number-1)\n",
    "\n",
    "        logging.warning(\"Extracting game %d\" % game_number)\n",
    "        for j in range(13):\n",
    "            logging.debug(\"    Extracting round %d\" % j)\n",
    "            cards = {'left':[],'up':[],'right':[],'down':[]} # initialize a dictionnary where we will add the contours corresponding to \n",
    "            # each cards\n",
    "\n",
    "            img=cv2.cvtColor(game[j],cv2.COLOR_RGB2GRAY)\n",
    "            n,thresh = cv2.threshold(img,150, 255, cv2.THRESH_BINARY) # treshold on the image\n",
    "\n",
    "            contours = measure.find_contours(thresh, level = 100) # find the contours\n",
    "            contours = sorted(contours, key=len, reverse=True)    # sort them so that we have the largest one at index 0\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(20): # check the 20 first contours to extract the cards contours\n",
    "                cards=check_card(contours[i],cards)\n",
    "            cards_final=[] # list with only one contour for each card (take the smallest)\n",
    "\n",
    "            # add a condition to be sure that we found a contour for the card. If not, give instead [0,0]\n",
    "            if len(cards['down'])!=0:\n",
    "                cards_final.append(cards['down'][-1])\n",
    "            else:\n",
    "                cards_final.append([0,0])\n",
    "            if len(cards['right'])!=0:\n",
    "                cards_final.append(cards['right'][-1])\n",
    "            else:\n",
    "                cards_final.append([0,0])\n",
    "\n",
    "            if len(cards['up'])!=0:\n",
    "                cards_final.append(cards['up'][-1])\n",
    "            else:\n",
    "                cards_final.append([0,0])\n",
    "            if len(cards['left'])!=0:\n",
    "                cards_final.append(cards['left'][-1])\n",
    "            else:\n",
    "                cards_final.append([0,0])\n",
    "\n",
    "\n",
    "            # GET THE FOUR CARDS IN THE SAME ORIENTATION : \n",
    "            cardsRGB, cardsgray = crop_with_ctr(cards_final, game[j], img, False)\n",
    "            cardsgray, cardsRGB = rotate_card(cardsgray,cardsRGB, plot=False) # rotate the cards with the good orientation \n",
    "\n",
    "            # EXTRACT THE FEATURES : \n",
    "            number_symbols=[]\n",
    "            number_images=[]\n",
    "\n",
    "            for i in range(4):\n",
    "\n",
    "                n,imthresh = cv2.threshold(cardsgray[i],145, 255, cv2.THRESH_BINARY)\n",
    "                # find again the contours to get the number and the symbol : \n",
    "                contours = measure.find_contours(imthresh, level = 100) # find the contours\n",
    "                contours = sorted(contours, key=len, reverse=True)  \n",
    "\n",
    "                number_image=find_number(contours,imthresh)\n",
    "                number_images.append(number_image)\n",
    "\n",
    "                \n",
    "            final_number.append(number_images)\n",
    "            \n",
    "    return final_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:17:52.838688Z",
     "start_time": "2021-06-02T16:17:52.396370Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_truth():\n",
    "    \"\"\"\n",
    "    Extract ground truth from all cards played (7 games, 13 rounds, 4 cards)\n",
    "    \n",
    "    OUTPUTS:\n",
    "        - all cards played\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    cgt_rank =[]\n",
    "\n",
    "    for i in range(1,8):\n",
    "        # Load ground truth from game i\n",
    "        cgt = pd.read_csv('./Data/game'+ str(i) + '/game'+ str(i) + '.csv', index_col=0)\n",
    "        cgt_rank.append(cgt[['P1', 'P2', 'P3', 'P4']].values)\n",
    "    t = np.array(cgt_rank)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Extract Jacks Queen and King to add it to mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:17:53.024788Z",
     "start_time": "2021-06-02T16:17:53.012820Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_signs(t,final_number):\n",
    "    \"\"\"\n",
    "    From all cards played extract jacks, queens and kings signs \n",
    "    \n",
    "    INPUTS:\n",
    "        - t: ground truth\n",
    "        - final_number: all cards played\n",
    "    \n",
    "    OUTPUTS:\n",
    "        - signs: images of signs\n",
    "        - signs_labels: labels of signs (\"J\", \"Q\", or \"K\")\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    signs = []\n",
    "    signs_labels = []\n",
    "\n",
    "    for S,R in zip([\"K\",\"Q\",\"J\"],[12,11,10]):\n",
    "        ids = np.argwhere((t==S+\"C\") |(t==S+\"H\") |(t==S+\"S\") |(t==S+\"D\"))\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            id=ids[i]\n",
    "            signs.append(255-final_number[id[0]*13+id[1]][id[2]])\n",
    "            signs_labels.append(R)\n",
    "\n",
    "        \n",
    "        \n",
    "    return signs, signs_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Mnist neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T10:07:32.929965Z",
     "start_time": "2021-05-19T10:07:32.895059Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "def convert_to_one_hot_labels(input, target):\n",
    "    \"\"\"\n",
    "    Convert labels to one hot encoding\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp = input.new_zeros(target.size(0), target.max() + 1)\n",
    "    tmp.scatter_(1, target.view(-1, 1), 1.0)\n",
    "    return tmp\n",
    "\n",
    "def load_data(N,one_hot_labels = False, normalize = False, Signs = True):\n",
    "    \"\"\"\n",
    "    Load images to train the model on.\n",
    "    Images are randomly selected from MNIST dataset. \n",
    "    if asked: Jacks, Queens and Kings signs are added to the dataset\n",
    "    \n",
    "    INPUTS:\n",
    "        - N: number of train and test images to load\n",
    "        - one_hot_labels: output form of targets \n",
    "                                true: will be converted to one hot labels (example 0-4 : 3 = [0,0,0,1,0])\n",
    "                                false: will not be converted to one hot labels  (example 0-4 : 3 = [3])\n",
    "        - normalize: boolean to normalize data (changing data to mean = 0 and standard deviation = 1)\n",
    "        - signs: boolean to add Jacks, Queens and Kings signs are added to the dataset.\n",
    "    \n",
    "    OUTPUTS:\n",
    "        - train_input, test_input: train and test images\n",
    "        - train_target, test_target: train and test labels\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    global signs, signs_label\n",
    "    \n",
    "\n",
    "    data_dir = os.path.join(os.pardir,'project', 'data')\n",
    "\n",
    "    \n",
    "    mnist_train_set = datasets.MNIST(data_dir , train = True, download = True)\n",
    "    mnist_test_set = datasets.MNIST(data_dir , train = False, download = True)\n",
    "\n",
    "    train_input = mnist_train_set.data.view(-1, 1, 28, 28).float()\n",
    "    train_target = mnist_train_set.targets\n",
    "    test_input = mnist_test_set.data.view(-1, 1, 28, 28).float()\n",
    "    test_target = mnist_test_set.targets\n",
    "        \n",
    "    logging.debug(\"Reducing dataset to %d train and %d test randomly selected sample\" % (N,N))\n",
    "    \n",
    "    if Signs:\n",
    "        old_N=N\n",
    "        N = int(np.floor(0.77*N))\n",
    "        logging.debug(\"Adding King Queen Jacks to dataset.\")\n",
    "                      \n",
    "    idx = torch.ones(train_input.size(0)).multinomial(num_samples=N, replacement=True)\n",
    "    train_input = torch.index_select(train_input, 0, idx)\n",
    "    train_target = torch.index_select(train_target, 0, idx)\n",
    "    \n",
    "    idx = torch.ones(test_input.size(0)).multinomial(num_samples=N, replacement=True)\n",
    "    test_input = torch.index_select(test_input, 0, idx)\n",
    "    test_target = torch.index_select(test_target, 0, idx)\n",
    "    \n",
    "    if Signs:\n",
    "        sz = old_N-N\n",
    "        w = int(np.ceil(sz/len(signs)))\n",
    "        signs_temp = signs*w\n",
    "        signs_label_temp = signs_label*w\n",
    "        \n",
    "        ##########################################################################\n",
    "        # WE SHOULD RANDOMIZE SIGNS AND SIGNS LABEL , WITHOUT WE HAVE LESS JACKS #\n",
    "        ##########################################################################\n",
    "        train_input = torch.cat((train_input, torch.tensor(signs_temp[0:sz]).unsqueeze(1)), 0)\n",
    "        train_target = torch.cat((train_target, torch.tensor(signs_label_temp[0:sz])), 0)\n",
    "        test_input = torch.cat((test_input, -torch.tensor(signs_temp[0:sz]).unsqueeze(1)), 0)\n",
    "        test_target = torch.cat((test_target, torch.tensor(signs_label_temp[0:sz])), 0)\n",
    "        \n",
    "        p = torch.randperm(old_N)\n",
    "        train_input = train_input[p]\n",
    "        train_target = train_target[p]\n",
    "        \n",
    "        p = torch.randperm(old_N)\n",
    "        test_input = test_input[p]\n",
    "        test_target = test_target[p]\n",
    "        \n",
    "\n",
    "    if one_hot_labels:\n",
    "        train_target = convert_to_one_hot_labels(train_input, train_target)\n",
    "        test_target = convert_to_one_hot_labels(test_input, test_target)\n",
    "\n",
    "    if normalize:\n",
    "        mu, std = train_input.mean(), train_input.std()\n",
    "        train_input.sub_(mu).div_(std)\n",
    "        test_input.sub_(mu).div_(std)\n",
    "\n",
    "    return train_input, train_target, test_input, test_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T10:07:35.114940Z",
     "start_time": "2021-05-19T10:07:35.087889Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# reset layer weights\n",
    "def reset_weights(m):\n",
    "    \"\"\"\n",
    "    Reset weights of all layer of a model\n",
    "    \n",
    "    INPUTS:\n",
    "        - model: model to reset weights\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            logging.debug(\"Reset trainable parameters of layer %s\" % layer)\n",
    "            layer.reset_parameters()\n",
    "\n",
    "def train_model(model, train_input, train_target, mini_batch_size,i, nb_epochs = 100):\n",
    "    \"\"\"\n",
    "    Train a model\n",
    "    \n",
    "    INPUTS:\n",
    "        - model: model to test\n",
    "        - train_input: Images to train model on\n",
    "        - train_target: ground to truth the model should find\n",
    "        - i: current round (for printing purposes)\n",
    "        - mini_batch_size: size of batch at training and testing (for RAM size)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "\n",
    "        logging.debug(\"Iteration : %2d, Epoch : %2d, Accumatedloss : %.6f\" % (i,e, acc_loss))\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    \"\"\"\n",
    "    Compute the numbers of errors made by model on a testing set (MNIST)\n",
    "    \n",
    "    INPUTS:\n",
    "        - model: model to test\n",
    "        - input: Mnist images to test model on\n",
    "        - target: ground to truth the model should find\n",
    "        - mini_batch_size: size of batch at training and testing (for RAM size)\n",
    "        \n",
    "    OUTPUTS:\n",
    "        - nb_errors: number of errors made by the model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors\n",
    "\n",
    "def train_round(model, N = 1000, rounds = 1, nb_epochs = 25, mini_batch_size = 100):\n",
    "    \"\"\"\n",
    "    Train a model multiple times (to make stats)\n",
    "\n",
    "    INPUTS:\n",
    "        - model: model to train\n",
    "        - N: number of train and test images\n",
    "        - rounds: number of rounds to make (for stats)\n",
    "        - nb_epochs: number of epochs the model will be trained each rounds\n",
    "        - mini_batch_size: size of batch at training and testing (for RAM size)\n",
    "        \n",
    "    OUTPUTS:\n",
    "        - test_errors_net: Percentage of errors made by the model at each rounds\n",
    "                            (allow to make external computation: boxplot, ...)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    global ground_T,numbers\n",
    "    logging.critical(\" Number of train images: %d | Number of epoch: %d | Number of rounds: %d (For stats)\" % (N,nb_epochs,rounds))\n",
    "    test_errors_net = []\n",
    "    execT =[]\n",
    "    for i in range(rounds):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Data randomization\n",
    "        train_input, train_target, test_input, test_target = load_data(N,one_hot_labels = True, normalize = True, Signs = False)\n",
    "            \n",
    "        # Weight reinitialization\n",
    "        #model.apply(reset_weights)\n",
    "        \n",
    "        # Model training\n",
    "        train_model(model, train_input, train_target, mini_batch_size,i, nb_epochs)\n",
    "        \n",
    "        # Computing errors and saving them\n",
    "        nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "        logging.warning(\"     Round : %2d, Test error: %5.2f%%\" % (i,(100 * nb_test_errors) / test_input.size(0)))\n",
    "        err = (100 * nb_test_errors) / test_input.size(0)\n",
    "        test_errors_net.append(err)\n",
    "        \n",
    "        # Save model for later\n",
    "        execT.append(time.time() - start_time)\n",
    "        save_path = './Model-data/M%.1f-Model-Net-I%d-E%d-R%d.pth' %(err,N,nb_epochs,i)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    test_errors_net = torch.tensor(test_errors_net)\n",
    "    execT = torch.tensor(execT).mean()\n",
    "    logging.critical(\"Test error mean: %4.1f%%, median: %4.1f%%, std_dev: %4.1f%%  |  Mean exec time: %2d min %.3f secs\" % (test_errors_net.mean(),test_errors_net.median(),test_errors_net.std(),execT//60,execT-(execT//60)*60))\n",
    "    return test_errors_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [neural network definition](#4.3-Neural-Network-for-mnist-numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:31:28.623007Z",
     "start_time": "2021-06-02T16:27:59.623765Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting game 1\n",
      "Extracting game 2\n",
      "Extracting game 3\n",
      "Extracting game 4\n",
      "Extracting game 5\n",
      "Extracting game 6\n",
      "Extracting game 7\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL : only main outputs\n",
    "# WARNING : main Outputs and secondary\n",
    "# DEBUG : full Outputs, and model loss\n",
    "logging.basicConfig(level=logging.WARNING, format='%(message)s')\n",
    "\n",
    "numbers = extract_card_number()\n",
    "ground_T = extract_truth()\n",
    "signs, signs_label = extract_signs(ground_T,numbers)\n",
    "\n",
    "all_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T10:46:11.173199Z",
     "start_time": "2021-05-19T10:10:19.670089Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net(200)\n",
    "all_errors.append(train_round(model,13000,2,200,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(200)\n",
    "all_errors.append(train_round(model,6500,2,200,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "all_errors.append(train_round(model,13000,3,200,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 NN performance assessment on game data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:32:22.214308Z",
     "start_time": "2021-06-02T16:32:22.180423Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_models(models, reload_images = False, print_extended = 0):\n",
    "    \"\"\"\n",
    "    Evalute a list of models on cards number. \n",
    "    Precisely on all the 364 numbers (7 games * 13 rounds * 4 cards)\n",
    "\n",
    "    INPUTS :\n",
    "        - models: name of the file containing the models parameters\n",
    "        - reload_images: boolean to choose if we need to reload all the card images (or not if it has already been done before)\n",
    "        - print_extended: integer to choose the type of printing:\n",
    "                                - 0: print model global accuracy\n",
    "                                - 1: print model global accuracy + all errors\n",
    "                                - 2: print model global accuracy + all errors + all answers\n",
    "    \"\"\"\n",
    "    global numbers,ground_T\n",
    "    \n",
    "    if reload_images:\n",
    "        numbers = extract_card_number()\n",
    "        ground_T = extract_truth()\n",
    "\n",
    "    numbers_tensor = torch.tensor(np.concatenate( numbers, axis=0))\n",
    "    numbers_tensor = numbers_tensor.unsqueeze(1)\n",
    "    numbers_tensor = (255-numbers_tensor).type(torch.DoubleTensor)\n",
    "\n",
    "    mu, std = numbers_tensor.mean(), numbers_tensor.std()\n",
    "    numbers_tensor.sub_(mu).div_(std)\n",
    "    numbers_tensor = numbers_tensor.type(torch.FloatTensor)\n",
    "    numbers_tensor\n",
    "\n",
    "    for model_data in models:\n",
    "        model = Net(200)\n",
    "        model.load_state_dict(torch.load(f'./Model-data/'+ model_data + '.pth'))\n",
    "        model.eval()\n",
    "\n",
    "        output = model(numbers_tensor)\n",
    "        _, predicted_classes = output.max(1)\n",
    "        predicted_classes = np.array(predicted_classes.view(-1,4)).astype(str)\n",
    "        predicted_classes = np.where(predicted_classes=='10', 'J', predicted_classes) \n",
    "        predicted_classes = np.where(predicted_classes=='11', 'Q', predicted_classes) \n",
    "        predicted_classes = np.where(predicted_classes=='12', 'K', predicted_classes)\n",
    "\n",
    "        from utils import evaluate_game\n",
    "        err = evaluate_game(predicted_classes, ground_T.reshape((91, 4)), mode_advanced=False)\n",
    "        errors = [''.join(row) for row in np.array([ e+d+c+\"   |   \"+a + \"-\" + b for a,b,c,d,e in zip(np.array([v[0] for v in ground_T.flatten()]),np.array([v[0] for v in predicted_classes.flatten()]),np.char.add(\", card: \",(np.mod(np.array(range(364)),4)+1).astype(str)),np.char.add(\", round: \",([\"%02d\" % a for a in (np.mod(np.array(range(364))//4,13)+1)])),np.char.add(\"Game: \",(np.mod(np.array(range(364))//4//13,7)+1).astype(str)))  if (a!=b)])]\n",
    "        \n",
    "        print('Global accuracy: %.1f%%' % (err*100))\n",
    "\n",
    "        if print_extended == 1:\n",
    "            print('\\nErrors: %d/%d\\nTruth-Result' % (len(errors),predicted_classes.shape[0]*predicted_classes.shape[1]))\n",
    "            print('\\n'.join(errors))\n",
    "\n",
    "        if print_extended >1:\n",
    "            print('\\nAll answers:\\nTruth-Result')\n",
    "            print('\\n'.join([','.join(row) for row in np.array([\"\\x1b[92m \" + a + \"-\" + b+ \" \\x1b[0m\" if (a==b) else \"\\x1b[91m \" + a + \"-\"+b+ \" \\x1b[0m\" for a,b in zip(np.array([v[0] for v in ground_T.flatten()]),np.array([v[0] for v in predicted_classes.flatten()]))]).reshape(predicted_classes.shape).tolist()]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:32:22.937115Z",
     "start_time": "2021-06-02T16:32:22.759590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global accuracy: 95.6%\n",
      "Global accuracy: 95.3%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = ['M23.8-Model-Net-I13000-E200-R2',\n",
    "         'M23.5-Model-Net-I65000-E200-R0']\n",
    "evaluate_models(models, reload_images = False, print_extended = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T16:32:23.642887Z",
     "start_time": "2021-06-02T16:32:23.525203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global accuracy: 95.3%\n",
      "\n",
      "Errors: 17/364\n",
      "Truth-Result\n",
      "Game: 1, round: 02, card: 3   |   9-4\n",
      "Game: 1, round: 08, card: 3   |   9-7\n",
      "Game: 1, round: 10, card: 4   |   9-1\n",
      "Game: 3, round: 04, card: 2   |   9-7\n",
      "Game: 3, round: 05, card: 3   |   9-4\n",
      "Game: 4, round: 02, card: 3   |   9-4\n",
      "Game: 4, round: 03, card: 3   |   9-7\n",
      "Game: 4, round: 07, card: 2   |   9-8\n",
      "Game: 4, round: 08, card: 2   |   2-1\n",
      "Game: 4, round: 08, card: 3   |   0-1\n",
      "Game: 4, round: 09, card: 2   |   5-2\n",
      "Game: 5, round: 01, card: 3   |   9-4\n",
      "Game: 6, round: 01, card: 2   |   5-2\n",
      "Game: 6, round: 06, card: 1   |   9-4\n",
      "Game: 6, round: 13, card: 2   |   9-7\n",
      "Game: 7, round: 02, card: 1   |   9-7\n",
      "Game: 7, round: 12, card: 2   |   9-4\n"
     ]
    }
   ],
   "source": [
    "models = ['M23.5-Model-Net-I65000-E200-R0']\n",
    "evaluate_models(models, reload_images = False, print_extended = 1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "-1",
   "nav_menu": {
    "height": "582px",
    "width": "578px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "681.85px",
    "left": "804px",
    "right": "20px",
    "top": "64px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
